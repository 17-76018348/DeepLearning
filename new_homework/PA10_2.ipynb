{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.10.2 MVLoR for One Sample\n",
    "\n",
    "PA 10.2에서 구현한 MVLoR for one sample의 parameter를 변경시켜<br>\n",
    "달라지는 결과값을 비교해 볼 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.1 \n",
    "PA 10.1에서 사용한 메소드를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f298d1bdca19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0miter_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_accum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_ticks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine_Function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0mBCE_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryCrossEntropy_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f298d1bdca19>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAffine_Function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_z1_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_dim' is not defined"
     ]
    }
   ],
   "source": [
    "class dataset_generator:\n",
    "    def __init__(self, feature_dim, n_sample = 300, noise_factor = 0., direction = 1):\n",
    "        self._feature_dim = feature_dim\n",
    "        self._n_sample = n_sample\n",
    "        self._noise_factor = noise_factor\n",
    "        self._direction = direction\n",
    "    \n",
    "        self._init_feature_dict()\n",
    "        self._init_t_th()\n",
    "    def _init_feature_dict(self):\n",
    "        self._feature_dict = dict()\n",
    "        for feature_idx in range(1, self._feature_dim + 1):\n",
    "            x_dict = {'mean':0, 'std':1}\n",
    "            self._feature_dict[feature_idx] = x_dict\n",
    "        \n",
    "    def _init_t_th(self):\n",
    "        self._t_th = [0] + [1 for i in range(self._feature_dim)]\n",
    "        \n",
    "    def set_feature_dict(self, feature_dict):\n",
    "        if len(feature_dict) != self._feature_dim:\n",
    "            class FeatureDictError(Exception):\n",
    "                pass\n",
    "            raise FeatureDictError('The length of \"feature_dict\" should be equal to \"feature_dim\"')\n",
    "        else:\n",
    "            self._feature_dict = feature_dict\n",
    "    def set_t_th(self, t_th_list):\n",
    "        if len(t_th_list) != len(self._t_th):\n",
    "            class t_th_Error(Exception):\n",
    "                pass\n",
    "            raise t_th_Error('The length of \"t_th_list\" should be equal to \"t_th_list\"')\n",
    "        else:\n",
    "            self._t_th = t_th_list\n",
    "    \n",
    "    def make_dataset(self):\n",
    "        x_data = np.zeros(shape = (self._n_sample, 1))\n",
    "        y = np.zeros(shape = (self._n_sample, 1))\n",
    "        \n",
    "        for feature_idx in range(1, self._feature_dim + 1):\n",
    "            feature_dict = self._feature_dict[feature_idx]\n",
    "            data = np.random.normal(loc = feature_dict['mean'], scale = feature_dict['std'],\n",
    "                                    size = (self._n_sample, 1))\n",
    "            x_data = np.hstack((x_data, data))\n",
    "            y += self._t_th[feature_idx]*data\n",
    "        y += self._t_th[0]\n",
    "        y_noise = y + self._noise_factor*np.random.normal(0, 1, (self._n_sample, 1))\n",
    "        \n",
    "        if self._direction > 0:\n",
    "            y_data = (y_noise > 0).astype(np.int)\n",
    "        else:\n",
    "            y_data = (y_noise < 0).astype(np.int)\n",
    "        \n",
    "        data = np.hstack((x_data, y_data))\n",
    "        return data\n",
    "class Affine_Function:\n",
    "    def __init__(self):\n",
    "        self._feature_dim = feature_dim\n",
    "        \n",
    "        self._z1_list = [None]*(self._feature_dim + 1)\n",
    "        self._z2_list = self._z1_list.copy()\n",
    "        \n",
    "        self._dz1_list, self._dz2_list = self._z1_list.copy(), self._z1_list.copy()\n",
    "        self._dth_list = self._z1_list.copy()\n",
    "        \n",
    "        self.node_imp()\n",
    "        self.random_initialization()\n",
    "        \n",
    "    def node_imp(self):\n",
    "        self._node1 = [None] + [nodes.mul_node() for _ in range(self._feature_dim)]\n",
    "        self._node2 = [None] + [nodes.plus_node() for _ in range(self._feature_dim)]\n",
    "    \n",
    "    def random_initialization(self):\n",
    "        r_feature_dim = 1/np.power(self._feature_dim, 0.5)\n",
    "        self._Th = np.random.uniform(low = -1*r_feature_dim,\n",
    "                                     high = r_feature_dim,\n",
    "                                     size = (self._feature_dim + 1,1))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for node_idx in range(1, self._feature_dim + 1):\n",
    "            self._z1_list[node_idx] = self._node1[node_idx].forward(self._Th[node_idx],\n",
    "                                                                    X[node_idx])\n",
    "        self._z2_list[1] = self._node2[1].forward(self._Th[0], self._z1_list[1])\n",
    "        for node_idx in range(2, self._feature_dim + 1):\n",
    "            self._z2_list[node_idx] = self._node2[node_idx].forward(self._z2_list[node_idx-1],\n",
    "                                                                    self._z1_list[node_idx])\n",
    "        return self._z2_list[-1]\n",
    "    \n",
    "    def backward(self, dz2_last, lr):\n",
    "        self._dz2_list[-1] = dz2_last\n",
    "        \n",
    "        for node_idx in reversed(range(1, self._feature_dim + 1)):\n",
    "            dz2, dz1 = self._node2[node_idx].backward(self._dz2_list[node_idx])\n",
    "            self._dz2_list[node_idx-1] = dz2\n",
    "            self._dz1_list[node_idx] = dz1\n",
    "        \n",
    "        self._dth_list[0] = self._dz2_list[0]\n",
    "        \n",
    "        for node_idx in reversed(range(1, self._feature_dim + 1)):\n",
    "            dth, _ = self._node1[node_idx].backward(self._dz1_list[node_idx])\n",
    "            self._dth_list[node_idx] = dth\n",
    "        \n",
    "        self._Th = self._Th - lr*np.array(self._dth_list).reshape(-1, 1)\n",
    "        return self._Th\n",
    "    \n",
    "    def get_Th(self):\n",
    "        return self._Th\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self._pred = None\n",
    "    \n",
    "    def forward(self, z):\n",
    "        self._pred = 1/(1 + np.exp(-1*z))\n",
    "        return self._pred\n",
    "    \n",
    "    def backward(self, dpred):\n",
    "        partial = self._pred * (1 - self._pred)\n",
    "        dz = dpred * partial\n",
    "        return dz\n",
    "class BinaryCrossEntropy_Loss:\n",
    "    def __init__(self):\n",
    "        self._y, self._pred = None, None\n",
    "    \n",
    "    def forward(self, y, pred):\n",
    "        self._y, self._pred = y, pred\n",
    "        loss = -1 * (y * np.log(self._pred) + (1 - y)*np.log(1 - pred))\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        dpred = (self._pred - self._y)/(self._pred * (1 - self._pred))\n",
    "        return dpred\n",
    "def result_tracker():\n",
    "    global iter_idx, check_freq\n",
    "    global th_accum, affine\n",
    "    \n",
    "    if iter_idx % check_freq == 0:\n",
    "        th_accum = np.hstack((th_accum, affine.get_Th()))\n",
    "        loss_list.append(1)\n",
    "    iter_idx += 1\n",
    "\n",
    "def plot_classifier():\n",
    "    p_idx = np.where(data[:,-1] > 0)\n",
    "    np_idx = np.where(data[:,-1] <= 0)\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,15))\n",
    "    ax = fig.add_subplot(projection = '3d')\n",
    "    \n",
    "    ax.plot(data[p_idx, 1].flat, data[p_idx,2].flat, data[p_idx, -1].flat, 'bo')\n",
    "    ax.plot(data[np_idx, 1].flat, data[np_idx,2].flat, data[np_idx, -1].flat, 'rX')\n",
    "    \n",
    "    ax.set_xlabel(r'$x_{1}$' + ' data', labelpad = 20)\n",
    "    ax.set_ylabel(r'$x_{2}$' + ' data', labelpad = 20)\n",
    "    ax.set_zlabel('y', labelpad = 20)\n",
    "    \n",
    "    f_th0, f_th1, f_th2 = th_accum[:,-1]\n",
    "    x1_range = np.linspace(np.min(data[:, 1]), np.max(data[:,1]), 100)\n",
    "    x2_range = np.linspace(np.min(data[:, 2]), np.max(data[:,2]), 100)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    \n",
    "    affine = X2*f_th2 + X1*f_th1 + f_th0\n",
    "    pred = sigmoid.forward(affine)\n",
    "    \n",
    "    ax.plot_wireframe(X1, X2, pred)\n",
    "\n",
    "def result_visualizer():\n",
    "    global th_accum, loss_list\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (30, 10))\n",
    "    fig.subplots_adjust(hspace = 0.3)\n",
    "    ax.set_title(r'$\\vec{\\theta}$' + ' Update')\n",
    "    \n",
    "    for feature_idx in range(feature_dim + 1):\n",
    "        \n",
    "        ax.plot(th_accum[feature_idx, :], label = r'$\\theta_{%d}$'%feature_idx)\n",
    "        \n",
    "    ax.legend()\n",
    "    iter_ticks = np.linspace(0, th_accum.shape[1],10).astype(np.int)\n",
    "    ax.set_xticks(iter_ticks)\n",
    "affine = Affine_Function()\n",
    "sigmoid = Sigmoid()\n",
    "BCE_loss = BinaryCrossEntropy_Loss()\n",
    "\n",
    "loss_list = []\n",
    "th_accum = affine.get_Th()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.2\n",
    "비교를 위해서 PA10_1에서 했던 Training을 동일하게 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 2\n",
    "noise_factor = 0.\n",
    "direction = 1\n",
    "n_sample = 100\n",
    "\n",
    "x_dict = {1:{'mean':0, 'std':1},\n",
    "          2:{'mean':0, 'std':1}}\n",
    "t_th_list = [0, 1, 1]\n",
    "\n",
    "epochs, lr = 100, 0.01\n",
    "iter_idx, check_freq = 0, 1\n",
    "\n",
    "data_gen = dataset_generator(feature_dim = feature_dim,\n",
    "                             n_sample = n_sample,\n",
    "                             noise_factor = noise_factor,\n",
    "                             direction = direction)\n",
    "data_gen.set_t_th(t_th_list)\n",
    "data_gen.set_feature_dict(x_dict)\n",
    "data = data_gen.make_dataset()\n",
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    for data_idx in range(data.shape[0]):\n",
    "        x, y =data[data_idx,:-1], data[data_idx, -1]\n",
    "        \n",
    "        z = affine.forward(x)\n",
    "        pred = sigmoid.forward(z)\n",
    "        l = BCE_loss.forward(y, pred)\n",
    "        \n",
    "        dpred = BCE_loss.backward()\n",
    "        dz = sigmoid.backward(dpred)\n",
    "        affine.backward(dz, lr)\n",
    "        \n",
    "        result_tracker()\n",
    "result_visualizer()\n",
    "plot_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
